{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad71f3ee-0f0b-45e6-a754-ed893d8deaaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from PIL import Image, ImageChops, ImageEnhance\n",
    "import cv2\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization\n",
    "from tensorflow.keras.applications import Xception\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f87f7e20-306a-48a9-a0f3-b1187696a9dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_to_ela_image(path, quality):\n",
    "    temp_filename = 'temp.jpg'\n",
    "    image = Image.open(path).convert('RGB')\n",
    "    image.save(temp_filename, 'JPEG', quality = quality)\n",
    "    temp_image = Image.open(temp_filename)\n",
    "    ela_image = ImageChops.difference(image, temp_image)\n",
    "    extrema = ela_image.getextrema()\n",
    "    max_diff = max([ex[1] for ex in extrema])\n",
    "    if max_diff == 0:\n",
    "        max_diff = 1\n",
    "    scale = 255.0 / max_diff\n",
    "    ela_image = ImageEnhance.Brightness(ela_image).enhance(scale)\n",
    "    return ela_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a019c5a-4c4e-4fda-9d2f-d987271aea8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3, 3), padding = 'same', activation = 'relu', input_shape = (224, 224, 3)))\n",
    "    model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3, 3), padding = 'same', activation = 'relu',))\n",
    "    model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters = 128, kernel_size = (3, 3), padding = 'same', activation = 'relu',))\n",
    "    model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation = 'relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation = 'softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5cc73ebe-f3d4-4032-a7eb-ef315b16f428",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_image(image_path):\n",
    "    return np.array(convert_to_ela_image(image_path, 90).resize(image_size)).flatten() / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5879aaeb-fb2b-49bb-9db3-5942edac906c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_size = (224, 224)\n",
    "X = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "49f3fe4c-4597-4338-b4c6-1cd4448deeaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define source paths\n",
    "authentic = 'data/casia/au/'\n",
    "tampered = 'data/casia/tp/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9a120f5f-dd07-411c-9440-55240cbef640",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 37\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk(authentic):\n",
    "  for filename in files:\n",
    "    file_path = os.path.join(root, filename)\n",
    "    if filename.lower().endswith(('jpg', 'png')):\n",
    "      X.append(prepare_image(file_path))\n",
    "      y.append(1)\n",
    "    if len(X)==3000:\n",
    "        break\n",
    "\n",
    "# random.shuffle(X)\n",
    "\n",
    "print(len(X), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cac2e21f-2341-4692-ac41-77fb5c8e057d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for root, dirs, files in os.walk(tampered):\n",
    "    for filename in files:\n",
    "        file_path = os.path.join(root, filename)\n",
    "        if filename.lower().endswith(('jpg', 'png', 'tif', 'tiff')):\n",
    "            X.append(prepare_image(file_path))\n",
    "            y.append(0)\n",
    "        if len(X)==4500:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "15978451-8068-4b39-b983-52e0ea9bd25f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = to_categorical(y, 2)\n",
    "X = X.reshape(-1, 224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "36875078-130c-42f7-80ad-cf4f8fb93662",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58 58\n",
      "15 15\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X, y, test_size = 0.2, random_state=5)\n",
    "X = X.reshape(-1,1,1,1)\n",
    "print(len(X_train), len(Y_train))\n",
    "print(len(X_val), len(Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "384aad0e-b08c-412f-bd89-d11f53ae6b1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.EarlyStopping at 0x7e294bfaa110>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5,mode='max', restore_best_weights=True)\n",
    "early_stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4915b69f-c540-4927-b41f-1e6e2b3bb29a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "epochs = 30\n",
    "batch_size = 32\n",
    "model.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "50f79aa3-3fd6-468f-ac4e-4cb34392f4a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2/2 [==============================] - 1s 440ms/step - loss: 4.5744 - accuracy: 0.6724 - val_loss: 0.5607 - val_accuracy: 0.6000\n",
      "Epoch 2/30\n",
      "2/2 [==============================] - 1s 340ms/step - loss: 10.7686 - accuracy: 0.7931 - val_loss: 0.5501 - val_accuracy: 0.8667\n",
      "Epoch 3/30\n",
      "2/2 [==============================] - 1s 333ms/step - loss: 6.1977 - accuracy: 0.9483 - val_loss: 0.8056 - val_accuracy: 0.9333\n",
      "Epoch 4/30\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 4.3796 - accuracy: 0.9483 - val_loss: 1.6416 - val_accuracy: 0.4000\n",
      "Epoch 5/30\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 3.6934 - accuracy: 0.9655 - val_loss: 1.1443 - val_accuracy: 0.4000\n",
      "Epoch 6/30\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.9807 - accuracy: 0.9828 - val_loss: 0.8396 - val_accuracy: 0.6667\n",
      "Epoch 7/30\n",
      "2/2 [==============================] - 1s 305ms/step - loss: 0.3975 - accuracy: 0.9828 - val_loss: 1.0210 - val_accuracy: 0.4000\n",
      "Epoch 8/30\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.4256 - accuracy: 1.0000 - val_loss: 1.4826 - val_accuracy: 0.4000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7e2950246650>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist = model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    batch_size = batch_size,\n",
    "    epochs = epochs,\n",
    "    validation_data = (X_val, Y_val),\n",
    "    callbacks = [early_stopping])\n",
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b3b7f7f8-c624-4e9b-8fd8-61d42a4e5231",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 55ms/step - loss: 0.8056 - accuracy: 0.9333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8056190609931946, 0.9333333373069763]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_val,Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "790a6954-63bf-4dd0-a74a-ed8ebbc07dd4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       1.00      0.89      0.94         9\n",
      "     Class 1       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.93      0.94      0.93        15\n",
      "weighted avg       0.94      0.93      0.93        15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_labels = np.argmax(Y_val, axis=1)\n",
    "y_pred_probs = model.predict(X_val)\n",
    "y_pred_labels = np.argmax(y_pred_probs, axis=1)\n",
    "print(classification_report(y_test_labels, y_pred_labels, target_names=['Class 0', 'Class 1']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
