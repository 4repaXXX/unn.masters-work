{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ee29b9b-f710-4f18-9bbf-9f2104b231ed",
   "metadata": {},
   "source": [
    "## EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6958084b-cc0b-471c-b865-c2a1fae1bed6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!c1.4\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import (\n",
    "    BatchNormalization,\n",
    "    Conv2D,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    GlobalAveragePooling2D,\n",
    "    MaxPool2D,\n",
    ")\n",
    "from keras.models import Model, Sequential\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import to_categorical\n",
    "from PIL import Image, ImageChops, ImageEnhance\n",
    "from scipy import stats\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
    "\n",
    "from data_prepare.dataset_tools import extract_zip_with_cleanup, prepare_and_save_data, create_data_generators\n",
    "from data_prepare.f1score import F1Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b224bebd-d2f0-4ff3-8ddb-e8dc81a378e7",
   "metadata": {},
   "source": [
    "### Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da814cc0-ecef-409a-a257-629be84772f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T05:12:04.789007Z",
     "iopub.status.busy": "2025-04-30T05:12:04.787709Z",
     "iopub.status.idle": "2025-04-30T05:12:04.821670Z",
     "shell.execute_reply": "2025-04-30T05:12:04.820741Z",
     "shell.execute_reply.started": "2025-04-30T05:12:04.788959Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model(input_shape=(224, 224, 3)):\n",
    "    base_model = EfficientNetB0(\n",
    "        weights='imagenet', \n",
    "        include_top=False, \n",
    "        input_shape=input_shape\n",
    "    )\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    model = Sequential(\n",
    "        [\n",
    "            base_model,\n",
    "            GlobalAveragePooling2D(),\n",
    "            Dropout(0.5),\n",
    "            Dense(1, activation=\"sigmoid\"),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=1e-3),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=[\n",
    "            tf.keras.metrics.BinaryAccuracy(name='accuracy'),  # Явное указание\n",
    "            tf.keras.metrics.Precision(name=\"precision\"),\n",
    "            tf.keras.metrics.Recall(name=\"recall\"),\n",
    "            tf.keras.metrics.AUC(name=\"auc\")\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return model, base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a9f6f3-5535-4091-b304-f1c15bfdf549",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T21:08:21.646234Z",
     "iopub.status.busy": "2025-04-29T21:08:21.644190Z",
     "iopub.status.idle": "2025-04-29T21:08:21.709711Z",
     "shell.execute_reply": "2025-04-29T21:08:21.708833Z",
     "shell.execute_reply.started": "2025-04-29T21:08:21.646194Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(train_generator, val_generator):\n",
    "    \"\"\"\n",
    "    Обучает модель на данных, загруженных в память\n",
    "\n",
    "    Parameters:\n",
    "        X_train (np.array): Тренировочные изображения\n",
    "        X_test (np.array): Тестовые изображения\n",
    "        y_train (np.array): Тренировочные метки\n",
    "        y_test (np.array): Тестовые метки\n",
    "\n",
    "    Returns:\n",
    "        tuple: (model, history) - обученная модель и история обучения\n",
    "    \"\"\"\n",
    "    model = build_model()\n",
    "\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        batch_size=32,\n",
    "        epochs=10,\n",
    "        validation_data=val_generator,\n",
    "        callbacks=[\n",
    "            ModelCheckpoint(\"best_model.h5\", monitor=\"val_pr_auc\", save_best_only=True),\n",
    "            EarlyStopping(monitor=\"val_loss\", patience=3),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33ed9dc-f34d-4329-baf3-302dd5f683b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T21:08:21.712784Z",
     "iopub.status.busy": "2025-04-29T21:08:21.711620Z",
     "iopub.status.idle": "2025-04-29T21:08:21.727039Z",
     "shell.execute_reply": "2025-04-29T21:08:21.726073Z",
     "shell.execute_reply.started": "2025-04-29T21:08:21.712731Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_archive_path = \"data/celeb/v1/\"\n",
    "fake_images_path, real_images_path = extract_zip_with_cleanup(image_archive_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6401e14-4904-45dc-96b7-fbe99287e59d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T21:08:21.728964Z",
     "iopub.status.busy": "2025-04-29T21:08:21.728069Z",
     "iopub.status.idle": "2025-04-29T21:08:21.740764Z",
     "shell.execute_reply": "2025-04-29T21:08:21.739664Z",
     "shell.execute_reply.started": "2025-04-29T21:08:21.728929Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dir, val_dir, test_dir = prepare_and_save_data(real_images_path, fake_images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adea2191-aa14-468e-a548-130eb9b7c8db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T21:08:21.743174Z",
     "iopub.status.busy": "2025-04-29T21:08:21.741934Z",
     "iopub.status.idle": "2025-04-29T21:08:22.052303Z",
     "shell.execute_reply": "2025-04-29T21:08:22.051349Z",
     "shell.execute_reply.started": "2025-04-29T21:08:21.743120Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9073 images belonging to 2 classes.\n",
      "Found 1944 images belonging to 2 classes.\n",
      "Found 1946 images belonging to 2 classes.\n",
      "\n",
      "Class indices: {'fake': 0, 'real': 1}\n",
      "Train samples: 9073\n",
      "Val samples: 1944\n",
      "Test samples: 1946\n"
     ]
    }
   ],
   "source": [
    "train_gen, val_gen, test_gen = create_data_generators(train_dir, val_dir, test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a518906-acd4-493e-a05b-a2c8444c93e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T05:12:11.945438Z",
     "iopub.status.busy": "2025-04-30T05:12:11.944375Z",
     "iopub.status.idle": "2025-04-30T05:15:52.227871Z",
     "shell.execute_reply": "2025-04-30T05:15:52.226826Z",
     "shell.execute_reply.started": "2025-04-30T05:12:11.945376Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 05:12:14.760649: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 05:12:20.037376: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_3/efficientnetb0/block2b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284/284 [==============================] - ETA: 0s - loss: 0.4569 - accuracy: 0.8340 - precision: 0.0526 - recall: 6.7159e-04 - auc: 0.5040"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 05:12:49.774575: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_pr_auc available, skipping.\n",
      "284/284 [==============================] - 43s 130ms/step - loss: 0.4569 - accuracy: 0.8340 - precision: 0.0526 - recall: 6.7159e-04 - auc: 0.5040 - val_loss: 0.4473 - val_accuracy: 0.8359 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4965\n",
      "Epoch 2/10\n",
      "284/284 [==============================] - ETA: 0s - loss: 0.4528 - accuracy: 0.8359 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5078WARNING:tensorflow:Can save best model only with val_pr_auc available, skipping.\n",
      "284/284 [==============================] - 34s 121ms/step - loss: 0.4528 - accuracy: 0.8359 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5078 - val_loss: 0.4478 - val_accuracy: 0.8359 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5267\n",
      "Epoch 3/10\n",
      "284/284 [==============================] - ETA: 0s - loss: 0.4545 - accuracy: 0.8359 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4891WARNING:tensorflow:Can save best model only with val_pr_auc available, skipping.\n",
      "284/284 [==============================] - 36s 127ms/step - loss: 0.4545 - accuracy: 0.8359 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4891 - val_loss: 0.4464 - val_accuracy: 0.8359 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5034\n",
      "Epoch 4/10\n",
      "284/284 [==============================] - ETA: 0s - loss: 0.4508 - accuracy: 0.8359 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5114WARNING:tensorflow:Can save best model only with val_pr_auc available, skipping.\n",
      "284/284 [==============================] - 35s 123ms/step - loss: 0.4508 - accuracy: 0.8359 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5114 - val_loss: 0.4522 - val_accuracy: 0.8359 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5015\n",
      "Epoch 5/10\n",
      "284/284 [==============================] - ETA: 0s - loss: 0.4521 - accuracy: 0.8359 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5042WARNING:tensorflow:Can save best model only with val_pr_auc available, skipping.\n",
      "284/284 [==============================] - 35s 122ms/step - loss: 0.4521 - accuracy: 0.8359 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5042 - val_loss: 0.4503 - val_accuracy: 0.8359 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5113\n",
      "Epoch 6/10\n",
      "284/284 [==============================] - ETA: 0s - loss: 0.4526 - accuracy: 0.8359 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5073WARNING:tensorflow:Can save best model only with val_pr_auc available, skipping.\n",
      "284/284 [==============================] - 34s 120ms/step - loss: 0.4526 - accuracy: 0.8359 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5073 - val_loss: 0.4495 - val_accuracy: 0.8359 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5363\n"
     ]
    }
   ],
   "source": [
    "trained_model, histories = train_model(train_gen, val_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4592d76d-2b55-4db8-8083-385a7868aeae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T05:16:22.338455Z",
     "iopub.status.busy": "2025-04-30T05:16:22.337138Z",
     "iopub.status.idle": "2025-04-30T05:16:22.442751Z",
     "shell.execute_reply": "2025-04-30T05:16:22.441357Z",
     "shell.execute_reply.started": "2025-04-30T05:16:22.338404Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Unable to serialize [2.0896919 2.1128857 2.1081853] to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12845/4277811527.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrained_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"efficient_deepfake_model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/json/__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mcheck_circular\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_circular\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_nan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mseparators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseparators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         **kw).encode(obj)\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/json/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/json/encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
      "\u001b[0;31mTypeError\u001b[0m: Unable to serialize [2.0896919 2.1128857 2.1081853] to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>."
     ]
    }
   ],
   "source": [
    "trained_model.save(\"efficient_deepfake_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a95ae48-b755-4341-836f-c6ee79d42aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = tf.keras.models.load_model(\"efficient_deepfake_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c20eb52d-badf-4d5c-85fb-c5bed5724a09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T21:15:57.965238Z",
     "iopub.status.busy": "2025-04-29T21:15:57.964228Z",
     "iopub.status.idle": "2025-04-29T21:16:12.436175Z",
     "shell.execute_reply": "2025-04-29T21:16:12.434831Z",
     "shell.execute_reply.started": "2025-04-29T21:15:57.965192Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 21:15:58.167842: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 14s 233ms/step - loss: 0.4537 - accuracy: 0.8356 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5196\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9292/3178579268.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_precision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_recall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrained_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nTest Accuracy: {test_auc:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "#!gt4.1\n",
    "test_loss, test_precision, test_recall, test_auc = trained_model.evaluate(test_gen)\n",
    "print(f\"\\nTest Accuracy: {test_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebef768-4f1b-4bc0-afc2-8e5b0827af98",
   "metadata": {},
   "source": [
    "### Finetume Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214e17f7-3d62-47d7-a74f-049354cb8118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_finetune(train_generator, val_generator, fine_tune=False, initial_epochs=10, fine_tune_epochs=10):\n",
    "    \"\"\"\n",
    "    Двухэтапное обучение с возможностью дообучения\n",
    "    \n",
    "    Parameters:\n",
    "        train_generator: генератор тренировочных данных\n",
    "        val_generator: генератор валидационных данных\n",
    "        fine_tune: выполнять ли дообучение\n",
    "        initial_epochs: количество эпох начального обучения\n",
    "        fine_tune_epochs: количество эпох дообучения\n",
    "    \"\"\"\n",
    "    model, base_model = build_xception_model()\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=initial_epochs,\n",
    "        validation_data=val_generator,\n",
    "        callbacks=[\n",
    "            ModelCheckpoint(\"initial_model.h5\", monitor=\"val_auc\", save_best_only=True, mode=\"max\"),\n",
    "            EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    if not fine_tune:\n",
    "        return model, history\n",
    "    \n",
    "    base_model.trainable = True\n",
    "    \n",
    "    for layer in base_model.layers[:100]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=1e-5),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\n",
    "            tf.keras.metrics.Precision(name=\"precision\"),\n",
    "            tf.keras.metrics.Recall(name=\"recall\"),\n",
    "            tf.keras.metrics.AUC(name=\"auc\"),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    fine_tune_history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=initial_epochs + fine_tune_epochs,\n",
    "        initial_epoch=history.epoch[-1] + 1,\n",
    "        validation_data=val_generator,\n",
    "        callbacks=[\n",
    "            ModelCheckpoint(\"fine_tuned_model.h5\", monitor=\"val_auc\", save_best_only=True, mode=\"max\"),\n",
    "            EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Объединяем истории обучения\n",
    "    full_history = {\n",
    "        k: history.history[k] + fine_tune_history.history[k]\n",
    "        for k in history.history\n",
    "    }\n",
    "    \n",
    "    return model, full_history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
