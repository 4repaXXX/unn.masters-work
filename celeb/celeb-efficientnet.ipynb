{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ee29b9b-f710-4f18-9bbf-9f2104b231ed",
   "metadata": {},
   "source": [
    "## EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6958084b-cc0b-471c-b865-c2a1fae1bed6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!c1.4\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from data_prepare.dataset_tools import extract_zip_with_cleanup, prepare_and_save_data\n",
    "from data_prepare.f1score import F1Score\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data_prepare.dataset_tools import extract_zip_with_cleanup, prepare_and_save_data\n",
    "from data_prepare.plots import plot_history, confusion_matrix_plot, roc_plot, precision_recall_plot\n",
    "from data_prepare.models import ModelType, DataLoader, NetFineTunedModel, FeatureExtractorModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dcace50-e633-4afc-870f-99d593de1f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "IMAGE_ARCHIVE_PATH=\"data/celeb/v1/\"\n",
    "MODELS_DIR = \"models\"\n",
    "RESULTS_DIR = \"results/net\"\n",
    "MODEL_TYPE=ModelType.EFFICIENTNET\n",
    "DATASET_OUTPUT_DIR='data/dataset'\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653da39e-23b4-4790-9268-0ed4cee0e297",
   "metadata": {},
   "source": [
    "## Pure model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c97329d6-d605-4b50-ba9a-e67bfbd82c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_archive_path = \"data/celeb/v1/\"\n",
    "fake_images_path, real_images_path = extract_zip_with_cleanup(image_archive_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d7bcf2fa-7b14-46e3-aaee-811052a39d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir, val_dir, test_dir = prepare_and_save_data(real_images_path, fake_images_path, output_dir=\"data/dataset/net\", target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "63fe5a30-e057-4244-915a-0dc786aedae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9075 images belonging to 2 classes.\n",
      "Found 1944 images belonging to 2 classes.\n",
      "Found 1946 images belonging to 2 classes.\n",
      "\n",
      "Class indices: {'fake': 0, 'real': 1}\n",
      "Train samples: 9075\n",
      "Val samples: 1944\n",
      "Test samples: 1946\n"
     ]
    }
   ],
   "source": [
    "train_gen, val_gen, test_gen = create_data_generators(train_dir, val_dir, test_dir, target_size=(224,224))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b224bebd-d2f0-4ff3-8ddb-e8dc81a378e7",
   "metadata": {},
   "source": [
    "### Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c20eb52d-badf-4d5c-85fb-c5bed5724a09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T21:15:57.965238Z",
     "iopub.status.busy": "2025-04-29T21:15:57.964228Z",
     "iopub.status.idle": "2025-04-29T21:16:12.436175Z",
     "shell.execute_reply": "2025-04-29T21:16:12.434831Z",
     "shell.execute_reply.started": "2025-04-29T21:15:57.965192Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 21:15:58.167842: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 14s 233ms/step - loss: 0.4537 - accuracy: 0.8356 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5196\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9292/3178579268.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_precision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_recall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrained_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nTest Accuracy: {test_auc:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "#!gt4.1\n",
    "test_loss, test_precision, test_recall, test_auc = trained_model.evaluate(test_gen)\n",
    "print(f\"\\nTest Accuracy: {test_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebef768-4f1b-4bc0-afc2-8e5b0827af98",
   "metadata": {},
   "source": [
    "## Finetune model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236f7beb-5343-4dce-9eb2-5557dffaad3d",
   "metadata": {},
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e95c5741-104d-4926-a93e-9ecc3b217c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/celeb/v1/fake data/celeb/v1/real\n",
      "data/dataset/net/train data/dataset/net/val data/dataset/net/test\n",
      "Found 112 images belonging to 2 classes.\n",
      "Found 1944 images belonging to 2 classes.\n",
      "Found 1946 images belonging to 2 classes.\n",
      "\n",
      "Class indices: {'fake': 0, 'real': 1}\n",
      "Train samples: 112\n",
      "Validation samples: 1944\n",
      "Test samples: 1946\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "data_loader = DataLoader(IMAGE_ARCHIVE_PATH, MODEL_TYPE)\n",
    "train_gen, val_gen, test_gen = data_loader.load_genrators(DATASET_OUTPUT_DIR)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "214e17f7-3d62-47d7-a74f-049354cb8118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aleksandr/opt/anaconda3/envs/deepfakedetection/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848ms/step - auc: 0.5730 - loss: 1.0176 - precision: 0.1170 - recall: 0.7960"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 5s/step - auc: 0.5852 - loss: 0.9727 - precision: 0.1222 - recall: 0.7641 - val_auc: 0.5474 - val_loss: 0.5362 - val_precision: 0.2857 - val_recall: 0.0564\n",
      "Epoch 2/3\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4s/step - auc: 0.8731 - loss: 0.3577 - precision: 0.4333 - recall: 0.8101 - val_auc: 0.5175 - val_loss: 0.5016 - val_precision: 0.1622 - val_recall: 0.0188\n",
      "Epoch 3/3\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4s/step - auc: 0.9619 - loss: 0.2698 - precision: 0.6417 - recall: 0.8087 - val_auc: 0.4956 - val_loss: 0.4810 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - auc: 0.8740 - loss: 0.2534 - precision: 0.6661 - recall: 0.7999"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - auc: 0.8772 - loss: 0.2538 - precision: 0.6395 - recall: 0.7854 - val_auc: 0.4943 - val_loss: 0.4810 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - auc: 0.9220 - loss: 0.2646 - precision: 0.6196 - recall: 0.7568"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4s/step - auc: 0.9221 - loss: 0.2564 - precision: 0.6188 - recall: 0.7509 - val_auc: 0.4961 - val_loss: 0.4808 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - auc: 0.9404 - loss: 0.2144 - precision: 0.6528 - recall: 0.4347"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - auc: 0.9324 - loss: 0.2206 - precision: 0.6111 - recall: 0.4205 - val_auc: 0.4975 - val_loss: 0.4807 - val_precision: 0.1250 - val_recall: 0.0063\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - auc: 0.9575 - loss: 0.1930 - precision: 0.5919 - recall: 0.6066"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - auc: 0.9562 - loss: 0.1931 - precision: 0.5826 - recall: 0.5944 - val_auc: 0.5003 - val_loss: 0.4807 - val_precision: 0.1000 - val_recall: 0.0063\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - auc: 0.9299 - loss: 0.2009 - precision: 0.6493 - recall: 0.5627"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - auc: 0.9232 - loss: 0.2057 - precision: 0.6306 - recall: 0.5411 - val_auc: 0.5026 - val_loss: 0.4807 - val_precision: 0.0870 - val_recall: 0.0063\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - auc: 0.9445 - loss: 0.2295 - precision: 0.5154 - recall: 0.4657"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m finetune = NetFineTunedModel(MODELS_DIR)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m finetune_model, finetune_history = finetune.fit(train_gen, val_gen, \u001b[32m3\u001b[39m, \u001b[32m7\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/education/unn.masters-work/celeb/data_prepare/models.py:281\u001b[39m, in \u001b[36mFineTunedModel.fit\u001b[39m\u001b[34m(self, train_generator, val_generator, initial_epochs, fine_tune_epochs)\u001b[39m\n\u001b[32m    269\u001b[39m     layer.trainable = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    271\u001b[39m \u001b[38;5;28mself\u001b[39m._model.compile(\n\u001b[32m    272\u001b[39m     optimizer=Adam(learning_rate=\u001b[32m1e-5\u001b[39m),\n\u001b[32m    273\u001b[39m     loss=\u001b[33m\"\u001b[39m\u001b[33mbinary_crossentropy\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    278\u001b[39m     ]\n\u001b[32m    279\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m281\u001b[39m fine_tune_history = \u001b[38;5;28mself\u001b[39m._model.fit(\n\u001b[32m    282\u001b[39m     train_generator,\n\u001b[32m    283\u001b[39m     epochs=initial_epochs + fine_tune_epochs,\n\u001b[32m    284\u001b[39m     initial_epoch=history.epoch[-\u001b[32m1\u001b[39m] + \u001b[32m1\u001b[39m,\n\u001b[32m    285\u001b[39m     validation_data=val_generator,\n\u001b[32m    286\u001b[39m     callbacks=[\n\u001b[32m    287\u001b[39m         ModelCheckpoint(\n\u001b[32m    288\u001b[39m             os.path.join(\u001b[38;5;28mself\u001b[39m._models_dir, \u001b[38;5;28mself\u001b[39m._funetune_model_name),\n\u001b[32m    289\u001b[39m             monitor=\u001b[33m\"\u001b[39m\u001b[33mval_auc\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    290\u001b[39m             save_best_only=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    291\u001b[39m             mode=\u001b[33m\"\u001b[39m\u001b[33mmax\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    292\u001b[39m         ),\n\u001b[32m    293\u001b[39m         EarlyStopping(\n\u001b[32m    294\u001b[39m             monitor=\u001b[33m\"\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    295\u001b[39m             patience=\u001b[32m5\u001b[39m,\n\u001b[32m    296\u001b[39m             restore_best_weights=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    297\u001b[39m         )\n\u001b[32m    298\u001b[39m     ]\n\u001b[32m    299\u001b[39m )\n\u001b[32m    301\u001b[39m full_history = {\n\u001b[32m    302\u001b[39m     k: history.history[k] + fine_tune_history.history[k]\n\u001b[32m    303\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m history.history\n\u001b[32m    304\u001b[39m }\n\u001b[32m    306\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._model, full_history\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/deepfakedetection/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(*args, **kwargs)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/deepfakedetection/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:395\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_eval_epoch_iterator\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    385\u001b[39m     \u001b[38;5;28mself\u001b[39m._eval_epoch_iterator = TFEpochIterator(\n\u001b[32m    386\u001b[39m         x=val_x,\n\u001b[32m    387\u001b[39m         y=val_y,\n\u001b[32m   (...)\u001b[39m\u001b[32m    393\u001b[39m         shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    394\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m val_logs = \u001b[38;5;28mself\u001b[39m.evaluate(\n\u001b[32m    396\u001b[39m     x=val_x,\n\u001b[32m    397\u001b[39m     y=val_y,\n\u001b[32m    398\u001b[39m     sample_weight=val_sample_weight,\n\u001b[32m    399\u001b[39m     batch_size=validation_batch_size \u001b[38;5;129;01mor\u001b[39;00m batch_size,\n\u001b[32m    400\u001b[39m     steps=validation_steps,\n\u001b[32m    401\u001b[39m     callbacks=callbacks,\n\u001b[32m    402\u001b[39m     return_dict=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    403\u001b[39m     _use_cached_eval_dataset=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    404\u001b[39m )\n\u001b[32m    405\u001b[39m val_logs = {\n\u001b[32m    406\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mval_\u001b[39m\u001b[33m\"\u001b[39m + name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs.items()\n\u001b[32m    407\u001b[39m }\n\u001b[32m    408\u001b[39m epoch_logs.update(val_logs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/deepfakedetection/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(*args, **kwargs)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/deepfakedetection/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:483\u001b[39m, in \u001b[36mTensorFlowTrainer.evaluate\u001b[39m\u001b[34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[39m\n\u001b[32m    481\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    482\u001b[39m     callbacks.on_test_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m483\u001b[39m     logs = \u001b[38;5;28mself\u001b[39m.test_function(iterator)\n\u001b[32m    484\u001b[39m     callbacks.on_test_batch_end(step, logs)\n\u001b[32m    485\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_evaluating:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/deepfakedetection/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:219\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    217\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    218\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m         opt_outputs = multi_step_on_iterator(iterator)\n\u001b[32m    220\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    221\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/deepfakedetection/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(*args, **kwargs)\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/deepfakedetection/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28mself\u001b[39m._call(*args, **kwds)\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/deepfakedetection/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = tracing_compilation.call_function(\n\u001b[32m    879\u001b[39m     args, kwds, \u001b[38;5;28mself\u001b[39m._variable_creation_config\n\u001b[32m    880\u001b[39m )\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/deepfakedetection/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m function._call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m    140\u001b[39m     flat_inputs, captured_inputs=function.captured_inputs\n\u001b[32m    141\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/deepfakedetection/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._inference_function.call_preflattened(args)\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/deepfakedetection/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28mself\u001b[39m.call_flat(*args)\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/deepfakedetection/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m._bound_context.call_function(\n\u001b[32m    252\u001b[39m         \u001b[38;5;28mself\u001b[39m.name,\n\u001b[32m    253\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    254\u001b[39m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.function_type.flat_outputs),\n\u001b[32m    255\u001b[39m     )\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/deepfakedetection/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1552\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1550\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1551\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1552\u001b[39m   outputs = execute.execute(\n\u001b[32m   1553\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1554\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   1555\u001b[39m       inputs=tensor_inputs,\n\u001b[32m   1556\u001b[39m       attrs=attrs,\n\u001b[32m   1557\u001b[39m       ctx=\u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1558\u001b[39m   )\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1560\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1561\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1562\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1566\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1567\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/deepfakedetection/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[32m     54\u001b[39m                                       inputs, attrs, num_outputs)\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "finetune = NetFineTunedModel(MODELS_DIR)\n",
    "finetune_model, finetune_history = finetune.fit(train_gen, val_gen, 3, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e690c7d-d217-4acf-8396-c9986f00d29f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m finetune_history_df = pd.DataFrame(finetune_histories.history)\n\u001b[32m      2\u001b[39m history_df.to_csv(\u001b[33m'\u001b[39m\u001b[33mresults/net/finetune_training_history.csv\u001b[39m\u001b[33m'\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "finetune_history_df = pd.DataFrame(finetune_histories.history)\n",
    "history_df.to_csv(RESULTS_DIR + '/finetune_training_history.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458d83a8-b590-4f36-948c-f5ad21d00c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# efficientnet_model_dir = os.path.join(MODELS_DIR, 'efficientnet_finetune_deepfake_model.h5')\n",
    "# finetune_model.save(efficientnet_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a26dbcd-3e55-41d8-8c0e-7f7b3f65e1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = finetune_trained_model.predict(test_gen)\n",
    "y_pred_df = pd.DataFrame(y_pred)\n",
    "y_pred_df.to_csv(RESULTS_DIR + '/y_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4075dcc8-376c-43c0-943d-493a8ff20821",
   "metadata": {},
   "source": [
    "### Analyze results for finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef652f3b-7eb9-4a7d-be34-32d1cb98786a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.read_csv('results/net/y_pred.csv')\n",
    "y_true = test_gen.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cef180-8038-42f8-a553-feb7f9d8a75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_loaded_history_df = pd.read_csv('results/finetune_training_history.csv')\n",
    "finetune_loaded_history = {'history': finetune_loaded_history_df.to_dict()}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
